{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from dataset import EpisodeDataset, collate_fn\n",
    "from model import Config, GPTModel\n",
    "from trainer import train_model, validate_model\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_idx = {(i, j): i * 7 + j + 1 for i in range(6) for j in range(7)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_idx['<pad>'] = 0  # Padding token\n",
    "\n",
    "vocab_size = 43\n",
    "block_size = 42 # Honestly this could probably be whatever\n",
    "embed_size = 512\n",
    "num_heads = 8\n",
    "num_layers = 8\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = '/Users/wizard/Downloads/TLSAV/Datasets'\n",
    "path = r'C:\\Users\\wmasi\\Documents\\Q-learning-gridworld\\TLSAV\\Datasets\\Connect4\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, '1\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent1 = pickle.load(f)\n",
    "with open(os.path.join(path, '2\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent2 = pickle.load(f)\n",
    "with open(os.path.join(path, '3\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent3 = pickle.load(f)\n",
    "with open(os.path.join(path, '4\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent4 = pickle.load(f)\n",
    "with open(os.path.join(path, '5\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent5 = pickle.load(f)\n",
    "with open(os.path.join(path, '6\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent6 = pickle.load(f)\n",
    "with open(os.path.join(path, '7\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent7 = pickle.load(f)\n",
    "with open(os.path.join(path, '8\\training_data\\training_games_125000.pkl'), 'rb') as f:\n",
    "    agent8 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "valid_ratio = 0.1\n",
    "\n",
    "d1 = len(agent1)\n",
    "d2 = len(agent2)\n",
    "d3 = len(agent3)\n",
    "d4 = len(agent4)\n",
    "d5 = len(agent5)\n",
    "d6 = len(agent6)\n",
    "d7 = len(agent7)\n",
    "d8 = len(agent8)\n",
    "\n",
    "train1 = agent1[:int(train_ratio * d1)]\n",
    "valid1 = agent1[int(train_ratio * d1):int((train_ratio + valid_ratio) * d1) ]\n",
    "test1 = agent1[int((train_ratio + valid_ratio) * d1): ]\n",
    "\n",
    "train2 = agent2[:int(train_ratio * d2)]\n",
    "valid2 = agent2[int(train_ratio * d2):int((train_ratio + valid_ratio) * d2) ]\n",
    "test2 = agent2[int((train_ratio + valid_ratio) * d2): ]\n",
    "\n",
    "train3 = agent3[:int(train_ratio * d3)]\n",
    "valid3 = agent3[int(train_ratio * d3):int((train_ratio + valid_ratio) * d3)]\n",
    "test3 = agent3[int((train_ratio + valid_ratio) * d3):]\n",
    "\n",
    "train4 = agent4[:int(train_ratio * d4)]\n",
    "valid4 = agent4[int(train_ratio * d4):int((train_ratio + valid_ratio) * d4)]\n",
    "test4 = agent4[int((train_ratio + valid_ratio) * d4):]\n",
    "\n",
    "train5 = agent5[:int(train_ratio * d5)]\n",
    "valid5 = agent5[int(train_ratio * d5):int((train_ratio + valid_ratio) * d5)]\n",
    "test5 = agent5[int((train_ratio + valid_ratio) * d5):]\n",
    "\n",
    "train6 = agent6[:int(train_ratio * d6)]\n",
    "valid6 = agent6[int(train_ratio * d6):int((train_ratio + valid_ratio) * d6)]\n",
    "test6 = agent6[int((train_ratio + valid_ratio) * d6):]\n",
    "\n",
    "train7 = agent7[:int(train_ratio * d7)]\n",
    "valid7 = agent7[int(train_ratio * d7):int((train_ratio + valid_ratio) * d7)]\n",
    "test7 = agent7[int((train_ratio + valid_ratio) * d7):]\n",
    "\n",
    "train8 = agent8[:int(train_ratio * d8)]\n",
    "valid8 = agent8[int(train_ratio * d8):int((train_ratio + valid_ratio) * d8)]\n",
    "test8 = agent8[int((train_ratio + valid_ratio) * d8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1588602\n",
      "198575\n",
      "198577\n"
     ]
    }
   ],
   "source": [
    "train = train1 + train2 + train3 + train4 + train5 + train6 + train7 + train8\n",
    "valid = valid1 + valid2 + valid3 + valid4 + valid5 + valid6 + valid7 + valid8\n",
    "test = test1 + test2 + test3 + test4 + test5 + test6 + test7 + test8\n",
    "\n",
    "print(len(train))\n",
    "print(len(valid))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EpisodeDataset(train, token_to_idx)\n",
    "valid_dataset = EpisodeDataset(valid, token_to_idx)\n",
    "test_dataset = EpisodeDataset(test, token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_main(save_directory = None, epochs = 15):\n",
    "    \n",
    "    accelerator = Accelerator()\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    config = Config(vocab_size, block_size, n_layer=num_layers, n_head=num_layers, n_embd=embed_size)\n",
    "    model = GPTModel(config)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs)\n",
    "    \n",
    "    train_loader, valid_loader, model, scheduler, optimizer = accelerator.prepare(train_loader, valid_loader, model, scheduler, optimizer)\n",
    "\n",
    "    epoch = 0\n",
    "\n",
    "    model_path = None\n",
    "    min_loss = 1e10\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        accelerator.print(f'Epoch {epoch}')\n",
    "\n",
    "        train_model(model, train_loader, optimizer, accelerator)\n",
    "        valid_loss = validate_model(model, valid_loader, accelerator)\n",
    "        scheduler.step()\n",
    "\n",
    "        if accelerator.is_main_process:\n",
    "            print(f'Validation Loss: {valid_loss:.8f}')\n",
    "\n",
    "            model_save_path = f\"Model_{epoch+1}.pth\"\n",
    "            accelerator.save(accelerator.unwrap_model(model).state_dict(), model_save_path)\n",
    "\n",
    "            if valid_loss < min_loss:\n",
    "                min_loss = valid_loss\n",
    "                model_path = model_save_path\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        shutil.copy(model_path, save_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 4 GPUs.\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12411/12411 [21:04<00:00,  9.81it/s]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5037913918495178\n",
      "Validation Loss: 0.47267327\n",
      "Epoch 1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/12411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12411/12411 [21:05<00:00,  9.80it/s]\n",
      "\n",
      "\n",
      "Training: 100%|██████████| 12411/12411 [21:05<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.46917539834976196\n",
      "Validation Loss: 0.46782213\n",
      "Epoch 2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/12411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12411/12411 [21:06<00:00,  9.80it/s]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.46598953008651733\n",
      "Validation Loss: 0.46719846\n",
      "Epoch 3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/12411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12411/12411 [21:02<00:00,  9.83it/s]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4646003246307373\n",
      "Validation Loss: 0.46600494\n",
      "Epoch 4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/12411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12411/12411 [21:01<00:00,  9.84it/s]\n",
      "\n",
      "Training: 100%|██████████| 12411/12411 [21:01<00:00,  9.84it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.46415749192237854\n",
      "Validation Loss: 0.46596977\n",
      "Epoch 5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/12411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12411/12411 [21:04<00:00,  9.82it/s]\n",
      "Training: 100%|██████████| 12411/12411 [21:04<00:00,  9.82it/s]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.46470674872398376\n",
      "Validation Loss: 0.46652344\n",
      "Epoch 6"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/12411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12411/12411 [21:02<00:00,  9.83it/s]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.465568482875824\n",
      "Validation Loss: 0.46668565\n",
      "Epoch 7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/12411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12411/12411 [21:03<00:00,  9.83it/s]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4658709466457367\n",
      "Validation Loss: 0.46701115\n",
      "Epoch 8"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/12411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12411/12411 [21:02<00:00,  9.83it/s]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.46543562412261963\n",
      "Validation Loss: 0.46701172\n",
      "Epoch 9"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/12411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12411/12411 [21:03<00:00,  9.82it/s]\n",
      "\n",
      "Training: 100%|██████████| 12411/12411 [21:03<00:00,  9.82it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4645695388317108\n",
      "Validation Loss: 0.46618474\n",
      "Epoch 10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/12411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12411/12411 [21:03<00:00,  9.83it/s]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.46356722712516785\n",
      "Validation Loss: 0.46592587\n",
      "Epoch 11"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/12411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12411/12411 [21:01<00:00,  8.37it/s]\n",
      "\n",
      "Training: 100%|██████████| 12411/12411 [21:01<00:00,  9.84it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4629788100719452\n",
      "Validation Loss: 0.46569046\n",
      "Epoch 12"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/12411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12411/12411 [21:03<00:00,  9.82it/s]\n",
      "\n",
      "Training: 100%|██████████| 12411/12411 [21:03<00:00,  9.82it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4629948139190674\n",
      "Validation Loss: 0.46567193\n",
      "Epoch 13"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/12411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12411/12411 [21:02<00:00,  9.83it/s]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4636186361312866\n",
      "Validation Loss: 0.46616063\n",
      "Epoch 14"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/12411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12411/12411 [21:02<00:00,  9.83it/s]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.46427425742149353\n",
      "Validation Loss: 0.46617603\n"
     ]
    }
   ],
   "source": [
    "notebook_launcher(train_main, (os.path.join(path, 'best_model'), 15), num_processes = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
